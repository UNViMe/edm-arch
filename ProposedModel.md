# Proposed Model

The proposed model will allow educational institutions to obtain complex knowledge by applying Machine Learning with a minimal presence of data scientists or with human resources that have only some of the skills that a data scientist would possess. 
![Fig. 1: Proposed Model](https://raw.githubusercontent.com/UNViMe/edm-arch/main/EDM-Model-FullProcess-Vertical-enUS.svg?token=GHSAT0AAAAAACXEXHRHFOJVR2E6CA773U3MZW3TX5A)
This new model will allow institutions to concentrate their efforts on theÂ analysis of the educational environment and possible solutions, that is, on both extremes of the model where educational institutions have the most expertise, allowing the proposed model to organize and guide the work on the central tasks.
To achieve the main goal, several methods, techniques and tools have been included to automate complex tasks in the EDM model, ranging from data preprocessing, feature preprocessing, choice of algorithms and their hyperparameters up to interpretability and explainability in all these tasks. For this model, a series of tasks are defined that must be fulfilled to achieve the objective and most of them have been automated to allow the use of ML (from task No. 6 to No. 14).
At the same time, the tasks of Data, Models and Results Explainability & Interpretability have been automated.
The tasks required to achieve the objective are presented in the following order:
1. Analysis of the Educational Environment to learn about the information systems available and the educational systems used.
2. Definition of the problem to be investigated (low performance, dropout, procrastination, teaching quality, lack of educational resources, teacher training, etc).
3. Setting the objectives to be met, e.g., identify at-risk students, evaluate the quality of content, teacher performance, develop referral systems, etc.
4. Definition of the data needed and accessible to the institution.
5. Acquisition and integration of data from the different sources that the educational community feeds through applications, the institutions' own software and widely used software -such as, scholarships, University Information System (SIU), etc-.
6. Exploratory data analysis allows for the explicability of the acquired data (univariate or multivariate analysis, statistical and correlation analysis).
7. Data pre-processing. This particular task includes what is known as data munging (data cleaning and normalization) where tasks such as elimination of missing or duplicate data, inconsistencies, class balancing and outliers, among others, are automated.
8. Creation of a dataset (a set of separate, complete, consistent and updated data that serves as the basis for training an ML algorithm) for each educational problem.
9. Feature preprocessing is performed depending on the nature of the data (rescaling of numerical data, text processing, feature selection and creation, or categorical data processing). All these activities can be performed automatically by applying feature preprocessing, one-hot enconder, dummy coding or feature hashing.
10. If the dataset has a considerable number of features reduce the dimensionality by using methods such as Principal Component Analysis (PCA). In addition, if the dataset has features that do not provide knowledge to improve the model, new features can be artificially and automatically created from the current ones.
11. Choice of models and dataset sampling. Depending on the problem to be solved, it is decided whether to use supervised ML algorithms (classifiers and regressors) or unsupervised ML algorithms (modeling from clustering, association rules, etc.); and this choice will define the sampling techniques that can be used, such as train test split, train valid and test split, k-fold cross validation and all its variants. Moreover, in this instance, it is possible to choose to use intrinsically interpretable or agnostic models.
12. The search for hyperparameters that optimize the cost function of a model is a complex task that involves everything ranging from the choice of the learning rate, iterations, batch size, to the choice of the depth of a tree, or the C-value or kernel of a Support Vector Machine (SVM). This step can be performed manually or using different automated methods such as grid search, Bayesian optimization, evolutionary techniques or gradient descent.
13. To know the General Interpretability of the Models, a technique is applied that allows to know automatically which was the complete path (chosen hyperparameters, data preprocessing and adopted characteristics) chosen for the, for example, 20 best models, from which the results can continue to be adjusted, but only by training the models that obtained the best performance in the complete pipeline. This will allow to restrict the group of algorithms and their hyperparameters to be trained and to obtain better results in a shorter time.
14. To analyze the interpretability of the models, the type of methods should be selected, whether they are interpretable (linear regression, logistic, weight plot, effect plot, precision recall plot, Silhouette Coefficient, etc.) or independent of the model (PDP, Features Interaction, LIME, SHAP, etc.), in addition to deciding on a local or global interpretation, or both. Based on knowing which are the characteristics that most influenced the decision of the models and understanding that no algorithmic bias errors are made, the metrics of the results of the models considered are analyzed.
15. Model persistence. The effort carried out must be stored to avoid having to perform it again. This storage can be done in two different ways depending on the intentions of the institution. It is possible to store only the trained model or to store the whole pipeline or workflow.
16. The conclusion of the problems is in charge of a set of multidisciplinary professionals of the educational institution that will evaluate the magnitude of the characteristics (causes) that influence the result, and the metrics obtained and will propose solution alternatives. At the end of a period or academic cycle, the problem should be re-evaluated to see if any progress has been made. Regardless of the type of educational problem to be solved, this set of multidisciplinary professionals must, first of all, before making any decision, check that the proposed ethical standards and their national and international regulations have been met, namely, at a minimum: privacy, bias, misuse of data, interpretability and explainability of results. Only in the case of compliance with these ethical standards, they must conclude, on one hand, whether they are satisfied with the model(s) found in terms of performance metrics of accuracy (accuracy, precision, recall, f1, mse, smse, mae, etc.), timing (training and prediction) and transparency (design and algorithmic), and, on the other hand, given that the main causes for the existence or persistence of an educational problem are known, propose alternative solutions to be implemented, which may be either in the academic field (curricular or extracurricular) or in the economic and social field.
